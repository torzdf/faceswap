#! /usr/env/bin/python3
"""Objects used for extraction plugins, runners and pipeline """
from __future__ import annotations
import logging
import typing as T
from dataclasses import dataclass, field
from enum import IntEnum

import numpy as np
import numpy.typing as npt

from lib.align.aligned_face import batch_umeyama, LandmarkType, MEAN_FACE
from lib.align.pose import Batch3D
from lib.logger import parse_class_init, format_array
from lib.utils import get_module_objects

if T.TYPE_CHECKING:
    from lib.align.alignments import PNGHeaderSourceDict
    from lib.align.constants import CenteringType
    from lib.align.detected_face import DetectedFace

logger = logging.getLogger(__name__)


class ExtractSignal(IntEnum):
    """Signals to send to the extraction pipeline"""
    FLUSH = 1
    """Flush all queued items"""
    SHUTDOWN = 2
    """Flush all queued items and shutdown"""


class ExtractMedia:
    """An object that passes through the :class:`~plugins.extract.pipeline.Extractor` pipeline.

    Parameters
    ----------
    filename
        The base name of the original frame's filename
    image
        The original frame or a faceswap aligned face image
    detected_faces
        A list of :class:`~lib.align.DetectedFace` objects. Detected faces can be added
        later with :func:`add_detected_faces`. Setting ``None`` will default to an empty list.
        Default: ``None``
    source
        The full path to the source folder or video file. Default: ``None`` (Not provided)
    is_aligned
        ``True`` if the :attr:`image` is an aligned faceswap image otherwise ``False``. Used for
        face filtering with vggface2. Aligned faceswap images will automatically skip detection,
        alignment and masking. Default: ``False``
    passthrough
        ``True`` if this item is meant to be passed straight through the extraction pipeline with
        no batching or caching. for immediate return. Default: ``False``
    """
    def __init__(self,
                 filename: str,
                 image: np.ndarray,
                 detected_faces: list[DetectedFace] | None = None,
                 source: str | None = None,
                 is_aligned: bool = False,
                 passthrough: bool = False) -> None:
        logger.trace(parse_class_init(locals()))  # type:ignore[attr-defined]
        self._filename = filename
        self._image: np.ndarray | None = image
        self._source = source
        self._image_shape = T.cast(tuple[int, int, int], image.shape)
        self._detected_faces: list[DetectedFace] = ([] if detected_faces is None
                                                    else detected_faces)
        self._is_aligned = is_aligned
        self._passthrough = passthrough
        self._frame_metadata: PNGHeaderSourceDict | None = None
        self._name = __class__.__name__

    def __repr__(self) -> str:
        """Pretty print for logging"""
        params = {k[1:]: format_array(v) if isinstance(v, np.ndarray) else repr(v)
                  for k, v in self.__dict__.items()
                  if k not in ("_frame_metadata", "_name")}
        sparams = ", ".join(f"{k}={v}" for k, v in params.items())
        return f"{self.__class__.__name__}({sparams})"

    @property
    def filename(self) -> str:
        """The base name of the :attr:`image` filename."""
        return self._filename

    @property
    def image(self) -> np.ndarray:
        """The source frame for this object."""
        assert self._image is not None
        return self._image

    @property
    def source(self) -> str | None:
        """The source folder or video of the frame, if provided"""
        return self._source

    @property
    def image_shape(self) -> tuple[int, int, int]:
        """The shape of the stored :attr:`image`"""
        return self._image_shape

    @property
    def image_size(self) -> tuple[int, int]:
        """The (`height`, `width`) of the stored :attr:`image`"""
        return self._image_shape[:2]

    @property
    def detected_faces(self) -> list[DetectedFace]:
        """A list of :class:`~lib.align.DetectedFace` objects in the :attr:`image`"""
        return self._detected_faces

    @property
    def passthrough(self) -> bool:
        """``True`` if the contents of this item are meant to pass straight through the extraction
        pipeline for immediate return"""
        return self._passthrough

    @property
    def is_aligned(self) -> bool:
        """``True`` if :attr:`image` is an aligned faceswap image otherwise ``False``"""
        return self._is_aligned

    @property
    def frame_metadata(self) -> PNGHeaderSourceDict | None:
        """The frame metadata that has been added from an aligned image. ``None`` if metadata has
        not been added"""
        return self._frame_metadata

    def add_image(self, image: npt.NDArray[np.uint8]) -> None:
        """Add (and potentially replace) an image to this object.

        Parameters
        ----------
        image
            The image to add to the ExtractMedia object
        """
        logger.trace("[%s] Adding image for filename: '%s': %s",  # type:ignore[attr-defined]
                     self._name, self._filename, format_array(image))
        self._image = image

    def remove_image(self) -> None:
        """Delete the image and reset :attr:`image` to ``None``."""
        logger.trace("[%s] Removing image for filename: '%s'",  # type:ignore[attr-defined]
                     self._name, self._filename)
        del self._image
        self._image = None

    def add_frame_metadata(self, metadata: PNGHeaderSourceDict) -> None:
        """Add the source frame metadata from an aligned PNG's header data.

        Parameters
        ----------
        metadata
            The contents of the 'source' field in the PNG header
        """
        logger.trace("[%s] Adding PNG Source data for '%s': %s",  # type:ignore[attr-defined]
                     self._name, self._filename, metadata)
        dims = T.cast(tuple[int, int], metadata["source_frame_dims"])
        self._image_shape = (*dims, 3)
        self._frame_metadata = metadata


@dataclass
class ExtractorBatchAligned:
    """Dataclass for working with batches of aligned images

    Parameters
    ----------
    landmarks
        The face landmarks found for this batch in frame space or ``None`` if not available.
        Default: ``None`` (to be populated later)
    landmark_type
        The type of landmarks that the batch holds or ``None`` if not available.
        Default: ``None`` (to be populated later)
    """
    landmarks: npt.NDArray[np.float32] | None = None
    """The face landmarks found for this batch in frame space or ``None`` if not populated"""
    landmark_type: LandmarkType | None = None
    """The type of landmarks that the batch holds"""

    # The following "_cache_" attributes are cached on demand and accessed through their
    # corresponding "non _cache_" properties
    _cache_landmarks_normalized: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_matrices: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_offsets_legacy: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_offsets_face: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_offsets_head: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_rotation: npt.NDArray[np.float32] | None = field(init=False, default=None)
    _cache_translation: npt.NDArray[np.float32] | None = field(init=False, default=None)

    def __repr__(self) -> str:
        """Pretty print arrays"""
        params = {}
        for k, v in self.__dict__.items():
            key = k.replace("_cache_", "")
            if isinstance(v, np.ndarray):
                params[key] = format_array(v)
                continue
            params[key] = v
        sparams = ", ".join(f"{k}={v}" for k, v in params.items())
        return f"{self.__class__.__name__}({sparams})"

    @property
    def landmarks_normalized(self) -> npt.NDArray[np.float32]:
        """The normalized, aligned landmarks"""
        self._assert_landmarks()
        if self._cache_landmarks_normalized is not None:
            return self._cache_landmarks_normalized

        rot = self.matrices[:, :2, :2]
        trans = self.matrices[:, :2, 2]
        self._cache_landmarks_normalized = (T.cast(npt.NDArray[np.float32], self.landmarks)
                                            @ rot.transpose(0, 2, 1)
                                            + trans[:, None, :])

        return self._cache_landmarks_normalized

    @property
    def matrices(self) -> npt.NDArray[np.float32]:
        """The face alignment matrices to transform from frame space to normalized (0, 1) space"""
        self._assert_landmarks()
        if self._cache_matrices is not None:
            return self._cache_matrices

        self._cache_matrices = batch_umeyama(T.cast(np.ndarray, self.landmarks)[:, 17:],
                                             MEAN_FACE[LandmarkType.LM_2D_51],
                                             True).astype("float32")
        return self._cache_matrices

    @property
    def matrices_face(self) -> npt.NDArray[np.float32]:
        """The alignment matrices to transform from normalized legacy space (0, 1) to normalized
        face space"""
        self._assert_landmarks()
        mats = self.matrices.copy()
        mats[:, :2, 2] -= self.offsets_face
        return mats

    @property
    def matrices_head(self) -> npt.NDArray[np.float32]:
        """The alignment matrices to transform from normalized legacy space (0, 1) to normalized
        head space"""
        self._assert_landmarks()
        mats = self.matrices.copy()
        mats[:, :2, 2] -= self.offsets_head
        return mats

    @property
    def offsets_legacy(self) -> npt.NDArray[np.float32]:
        """The (N, x, y) offets for normalized (legacy) centering. This is always (0, 0) for all
        items in the batch"""
        self._assert_landmarks()
        if self._cache_offsets_legacy is None:
            self._cache_offsets_legacy = np.zeros((T.cast(np.ndarray, self.landmarks).shape[0], 2),
                                                  dtype="float32")
        return self._cache_offsets_legacy

    @property
    def offsets_face(self) -> npt.NDArray[np.float32]:
        """The (N, x, y) offets required to shift from normalized (legacy) centering to face
        centering"""
        self._assert_landmarks()
        if self._cache_offsets_face is None:
            self._cache_offsets_face = Batch3D.get_offsets("face", self.rotation, self.translation)
        return self._cache_offsets_face

    @property
    def offsets_head(self) -> npt.NDArray[np.float32]:
        """The (N, x, y) offets required to shift from normalized (legacy) centering to head
        centering"""
        self._assert_landmarks()
        if self._cache_offsets_head is None:
            self._cache_offsets_head = Batch3D.get_offsets("head", self.rotation, self.translation)
        return self._cache_offsets_head

    @property
    def rotation(self) -> npt.NDArray[np.float32]:
        """The estimated (N, 3, 1) rotation vectors"""
        self._assert_landmarks()
        if self._cache_rotation is not None:
            return self._cache_rotation

        rot_trans = Batch3D.solve_pnp(self.landmarks_normalized)
        self._cache_rotation = T.cast(npt.NDArray[np.float32], rot_trans[0])
        self._cache_translation = rot_trans[1]

        return self._cache_rotation

    @property
    def translation(self) -> npt.NDArray[np.float32]:
        """The estimated (N, 3, 1) translation vectors"""
        self._assert_landmarks()
        if self._cache_translation is not None:
            return self._cache_translation

        rot_trans = Batch3D.solve_pnp(self.landmarks_normalized)
        self._cache_rotation = rot_trans[0]
        self._cache_translation = T.cast(npt.NDArray[np.float32], rot_trans[1])

        return self._cache_translation

    def _assert_landmarks(self) -> None:
        """Ensure that landmark data is available

        Raises
        ------
        ValueError
            If landmark data is not available
        """
        if self.landmarks is None:
            raise ValueError("Aligned data cannot be calculated without landmarks")

    def __getitem__(self, indices: slice) -> ExtractorBatchAligned:
        """Obtain a subset of this batch object with the data given by the start and end indices

        Parameters
        ----------
        indices
            The (start, stop, end) slice for extracting from the batch

        Returns
        -------
        A batch object containing the data from this object for the given indices
        """
        retval = ExtractorBatchAligned(landmark_type=self.landmark_type)
        if self.landmarks is not None:
            retval.landmarks = self.landmarks[indices]

        for k, v in self.__dict__.items():
            if k.startswith("_cache_") and v is not None:
                setattr(retval, k, v[indices])

        return retval

    def append(self, batch: ExtractorBatchAligned) -> None:
        """Append the data from the given batch object to this batch object

        Parameters
        ----------
        batch
            The object containing data to be appended to this object
        """
        if batch.landmarks is not None:
            self.landmarks = (np.concatenate([self.landmarks, batch.landmarks])
                              if self.landmarks is not None else batch.landmarks)
            if self.landmark_type is None:
                self.landmark_type = batch.landmark_type

        for k, v in batch.__dict__.items():
            if k.startswith("_cache_") and v is not None:
                exist = getattr(self, k)
                val = None if exist is None else np.concatenate([exist, v])
                setattr(self, k, val)

    def apply_mask(self, mask: npt.NDArray[np.bool_]) -> None:
        """Apply a boolean mask to the batch object. ``True`` values are kept, ``False`` values
        are discarded

        Parameters
        ----------
        mask
            The boolean mask to apply to the object. Must be of size (landmarks, )
        """
        if np.all(mask):
            return

        if self.landmarks is not None:
            self.landmarks = self.landmarks[mask]

        for k, v in self.__dict__.items():
            if k.startswith("_cache_") and v is not None:
                setattr(self, k, v[mask])


@dataclass
class ExtractorBatchMask:
    """Dataclass for holding information about masks produced by the extraction pipeline

    Parameters
    ----------
    centering
        The centering type of the masks
    matrices
        The normalized matrices required to take the masks from (0, 1) to full frame
    storage_size
        The pixel size to store the mask at in the alignments file. Default: 0 (must be populated
        later)
    masks
        The masks for this batch. Default: empty array (must be populated later)
    """
    centering: CenteringType
    """The centering type of the masks"""
    matrices: npt.NDArray[np.float32]
    """The normalized matrices required to take the masks from (0, 1) to full frame"""
    storage_size: int = field(default=0)
    """The pixel size to store the mask at in the alignments file"""
    masks: npt.NDArray[np.uint8] = field(default_factory=lambda: np.empty((0, 0, 0),
                                                                          dtype="uint8"))
    """The masks for this batch"""

    def __repr__(self) -> str:
        """Pretty print arrays"""
        params = {k: format_array(v) if isinstance(v, np.ndarray) else repr(v)
                  for k, v in self.__dict__.items()}
        sparams = ", ".join(f"{k}={v}" for k, v in params.items())
        return f"{self.__class__.__name__}({sparams})"

    def __getitem__(self, indices: slice) -> ExtractorBatchMask:
        """Basic object slicing for splitting batches

        Parameters
        ----------
        indices
            The (start, stop, end) slice for extracting from the batch

        Returns
        -------
        The sliced data from this batch
        """
        return ExtractorBatchMask(self.centering,
                                  self.matrices[indices],
                                  storage_size=self.storage_size,
                                  masks=self.masks[indices])

    def append(self, mask_batch: ExtractorBatchMask) -> None:
        """Append the given mask batch object to this batch mask object

        Parameters
        ----------
        mask_batch
            The object containing data to be appended to this object
        """
        self.matrices = np.concatenate([self.matrices, mask_batch.matrices], axis=0)
        self.masks = np.concatenate([self.masks, mask_batch.masks], axis=0)

    def apply_mask(self, mask: npt.NDArray[np.bool_]) -> None:
        """Apply a boolean mask to the batch object. ``True`` values are kept, ``False`` values
        are discarded

        Parameters
        ----------
        mask
            The boolean mask to apply to the object. Must be of size (num_masks, )
        """
        if np.all(mask):
            return
        self.masks = self.masks[mask]
        self.matrices = self.matrices[mask]


@dataclass
class ExtractorBatch:  # pylint:disable=too-many-instance-attributes
    """Dataclass for holding a batch flowing through Extraction plugins.

    The batch size for post Detector plugins is not the same as the overall batch size.
    An image may contain 0 or more detected faces, and these need to be split and recombined
    to be able to utilize a plugin's internal batch size.

    Parameters
    ----------
    filenames
        The original frame filenames for the batch
    images
        The original frames
    sources
        The full path to the source folder or video file. Default: ``[]`` (Not provided)
    is_aligned
        ``True`` if :attr:`images` contains aligned faces. ``False`` if it contains full frames.
        Default: ``False``
    frame_sizes
        The original frame (height, width) dimensions that contained the aligned images when
        :attr:`images` are aligned faces. Default: ``None``
    frame_metadata
        The original frame meta data when aligned faces is ``True`` otherwise ``None``
    passthrough
        `True`` if the contents of this item are meant to pass straight through the extraction
        pipeline for immediate return
    """
    # Input required information
    filenames: list[str] = field(default_factory=list)
    """The original frame filenames"""
    images: list[np.ndarray] = field(default_factory=list)
    """The original frames"""
    sources: list[str | None] = field(default_factory=list)
    """The full paths to the source folder or video file. ``None`` if not provided"""
    is_aligned: bool = False
    """``True`` if :attr:`images` contains aligned faces. ``False`` for full frames"""
    frame_sizes: list[tuple[int, int]] | None = None
    """The original frame (heights, widths) when the images are aligned faces"""
    frame_metadata: list[PNGHeaderSourceDict] | None = None
    """The original frame metadata when aligned faces is ``True`` otherwise ``None``"""
    passthrough: bool = False
    """Whether this item should pass straight through the pipeline for immediate return"""

    # Final data for output
    bboxes: npt.NDArray[np.int32] = field(init=False,
                                          default_factory=lambda: np.empty((0, 4), dtype="int32"))
    """The bounding boxes found for this batch"""
    aligned: ExtractorBatchAligned = field(init=False, default_factory=ExtractorBatchAligned)
    """Holds the face landmarks found for this batch any any aligned data"""
    masks: dict[str, ExtractorBatchMask] = field(init=False, default_factory=dict)
    """The masks for this batch"""
    identities: dict[str, npt.NDArray[np.float32]] = field(init=False, default_factory=dict)
    """The identity matrices for face recognition found for this batch"""

    # Internal batch structure
    frame_ids: npt.NDArray[np.int32] = field(init=False,
                                             default_factory=lambda: np.empty((0, ),
                                                                              dtype="int32"))
    """A mapping of each box to which frame they came from"""

    # Internal holder for passing data between processes. Deleted at output from each plugin
    data: np.ndarray = field(init=False)
    """The data for this batch that has been populated by a processing step for ingestion by the
    next processing step. Internally populated. Cleared at the end of each plugin"""
    matrices: npt.NDArray[np.float32] = field(init=False)
    """Transformation matrices for taking points from model input space to frame space. Cleared at
    the end of each plugin"""

    def __repr__(self) -> str:
        """Pretty print arrays"""
        params = {}
        for k, v in self.__dict__.items():
            if k == "images":
                params[k] = [format_array(x) for x in v]
                continue
            if k == "identities" and isinstance(v, dict):
                params[k] = {key: format_array(val) for key, val in v.items()}
                continue
            if isinstance(v, np.ndarray) and v.dtype == np.object_:
                params[k] = [format_array(x) for x in v]
                continue
            if isinstance(v, np.ndarray):
                params[k] = format_array(v)
                continue
            params[k] = v

        sparams = ", ".join(f"{k}={v}" for k, v in params.items())
        return f"{self.__class__.__name__}({sparams})"

    def __post__init__(self) -> None:
        """Populate sources if not provided"""
        if not self.sources:
            self.sources = [None for _ in range(len(self.filenames))]

    @property
    def landmarks(self) -> npt.NDArray[np.float32] | None:
        """The face landmarks found for this batch in frame space or ``None`` if not populated"""
        return self.aligned.landmarks

    @landmarks.setter
    def landmarks(self, value: npt.NDArray) -> None:
        """Set the landmarks attribute in the underlining ExtractorBatchAlign object

        Parameters
        ----------
        value
            The landmarks to set
        """
        self.aligned.landmarks = value

    @property
    def landmark_type(self) -> LandmarkType | None:
        """The landmark type foundfor this batch or ``None`` if not populated"""
        return self.aligned.landmark_type

    @landmark_type.setter
    def landmark_type(self, value: LandmarkType) -> None:
        """Set the landmark_type attribute in the underlining ExtractorBatchAlign object

        Parameters
        ----------
        value
            The landmark_type to set
        """
        self.aligned.landmark_type = value

    @property
    def lengths(self) -> npt.NDArray[np.int32]:
        """The number of bboxes that belong to each frame"""
        if self.frame_ids.size == 0:
            return np.zeros((len(self.images)), dtype="int32")
        return np.bincount(self.frame_ids, minlength=len(self.images)).astype("int32")

    def __getitem__(self, indices: slice) -> ExtractorBatch:
        """Obtain a subset of this batch object with the data given by the start and end indices

        Parameters
        ----------
        indices
            The (start, stop, end) slice for extracting from the batch

        Returns
        -------
        A batch object containing the data from this object for the given indices
        """
        assert not self.passthrough, "Passthrough batches can't be split"
        frame_ids = self.frame_ids[indices].copy()
        # If requesting the first bbox, we select all frames from the start
        frame_start = 0 if indices.start == 0 else frame_ids[0]

        frame_end = frame_ids[-1] + 1
        if indices.stop < self.bboxes.shape[0] and self.frame_ids[indices.stop] > frame_end:
            # catch any zero box frames between now and next split request
            frame_end = self.frame_ids[indices.stop]

        frame_sizes = None if self.frame_sizes is None else self.frame_sizes[frame_start:frame_end]
        frame_metadata = (None if self.frame_metadata is None
                          else self.frame_metadata[frame_start:frame_end])
        retval = ExtractorBatch(self.filenames[frame_start:frame_end],
                                self.images[frame_start:frame_end],
                                sources=self.sources[frame_start:frame_end],
                                is_aligned=self.is_aligned,
                                frame_sizes=frame_sizes,
                                frame_metadata=frame_metadata)
        retval.bboxes = self.bboxes[indices]
        retval.aligned = self.aligned[indices]
        retval.masks = {k: v[indices] for k, v in self.masks.items()}
        retval.identities = {k: v[indices] for k, v in self.identities.items()}

        if indices.start > 0:
            frame_ids -= frame_ids[0]  # Reset to zero
        retval.frame_ids = frame_ids

        if self.landmarks is not None:
            retval.landmarks = self.landmarks[indices]

        return retval

    def _populate_batch(self, batch: ExtractorBatch) -> None:
        """Populate this batch with the data from the incoming batch when this batch is empty

        Parameters
        ----------
        batch
            The object containing data to populate to this object
        """
        for k, v in batch.__dict__.items():
            setattr(self, k, v)

    def append(self, batch: ExtractorBatch) -> None:
        """Append the data from the given batch object to this batch object

        Parameters
        ----------
        batch
            The object containing data to be appended to this object
        """
        assert not self.passthrough, "Passthrough batches can't be split"
        if not self.filenames:
            self._populate_batch(batch)
            return
        frame_offset = len(self.filenames)
        if self.filenames[-1] == batch.filenames[0]:
            frame_offset -= 1  # We are still on the same frame
            if not np.any(self.images[-1]) and np.any(batch.images[0]):
                # Image was stripped for the faces in this batch, but exist for incoming batch
                self.images[-1] = batch.images[0]
        batch.frame_ids += frame_offset

        existing_filenames = self.filenames[:]
        self.filenames.extend(f for f in batch.filenames if f not in existing_filenames)
        self.images.extend(batch.images[i] for i, f in enumerate(batch.filenames)
                           if f not in existing_filenames)
        self.sources.extend(batch.sources[i] for i, f in enumerate(batch.filenames)
                            if f not in existing_filenames)

        if self.frame_sizes is not None and batch.frame_sizes is not None:
            self.frame_sizes.extend(batch.frame_sizes[i] for i, f in enumerate(batch.filenames)
                                    if f not in existing_filenames)
        if self.frame_metadata is not None and batch.frame_metadata is not None:
            self.frame_metadata.extend(batch.frame_metadata[i]
                                       for i, f in enumerate(batch.filenames)
                                       if f not in existing_filenames)

        self.bboxes = np.concatenate([self.bboxes, batch.bboxes])
        self.frame_ids = np.concatenate([self.frame_ids, batch.frame_ids])
        self.aligned.append(batch.aligned)

        for name, masks in batch.masks.items():
            if name in self.masks:
                self.masks[name].append(masks)
            else:
                self.masks[name] = masks

        for name, identities in batch.identities.items():
            self.identities[name] = (np.concatenate([self.identities[name], identities])
                                     if name in self.identities
                                     else identities)

    def from_detected_faces(self, faces: list[DetectedFace]) -> None:
        """Populate an ExtractorBatch with the contents of a DetectedFace object.

        Parameters
        ----------
        faces
            The DetectedFace objects to populate this batch

        Raises
        ------
        ValueError
            If attempting to add detected faces without pre-populating filename and image or if
            bounding boxes pre-exist or if more than one frame is held in this batch
        """
        if not self.filenames:
            raise ValueError("Filenames must be populated prior to adding detected faces")
        if not self.images:
            raise ValueError("Images must be populated prior to adding detected faces")
        if len(self.filenames) != len(self.images) != 1:
            raise ValueError("Only 1 filename and image should be the batch")
        if np.any(self.bboxes):
            raise ValueError("An empty ExtractorBatch object is required to add detected faces")
        self.frame_ids = np.fromiter((0 for _ in range(len(faces))), dtype="int32")
        self.aligned.landmark_type = LandmarkType.from_shape(T.cast(tuple[int, int],
                                                             faces[0].landmarks_xy.shape))
        num_faces = len(faces)
        self.bboxes = np.empty((num_faces, 4), dtype="int32")
        self.aligned.landmarks = np.empty((num_faces, *faces[0].landmarks_xy.shape),
                                          dtype="float32")
        self.identities = {k: np.empty((num_faces, *v.shape), dtype="float32")
                           for k, v in faces[0].identity.items()}
        self.masks = {
            k: ExtractorBatchMask(v.stored_centering,
                                  np.empty((num_faces, 2, 3), dtype="float32"),
                                  storage_size=v.stored_size,
                                  masks=np.empty((num_faces, v.stored_size, v.stored_size),
                                                 dtype="uint8"))
            for k, v in faces[0].mask.items()
            }
        for i, f in enumerate(faces):
            self.bboxes[i] = np.array([f.left, f.top, f.right, f.bottom], dtype="int32")
            self.aligned.landmarks[i] = f.landmarks_xy
            for k, v in f.identity.items():
                self.identities[k][i] = v
            for k, v in f.mask.items():
                mask = self.masks[k]
                mask.matrices[i] = v.affine_matrix
                mask.masks[i] = v.mask[:, :, 0]

    def apply_mask(self, mask: npt.NDArray[np.bool_]) -> None:
        """Apply a boolean mask to the batch object. ``True`` values are kept, ``False`` values
        are discarded

        Parameters
        ----------
        mask
            The boolean mask to apply to the object. Must be of size (num_boxes, )
        """
        if np.all(mask):
            return

        self.bboxes = self.bboxes[mask]
        self.frame_ids = self.frame_ids[mask]
        self.aligned.apply_mask(mask)

        if self.masks:
            for v in self.masks.values():
                v.apply_mask(mask)

        if self.identities:
            self.identities = {k: v[mask] for k, v in self.identities.items()}


__all__ = get_module_objects(__name__)
